{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hypotension.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIB+UjXTb8flHqGKp0I7Z3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitaldb/pyvital/blob/master/hypotension.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fasr2v3HjCtw",
        "colab_type": "text"
      },
      "source": [
        "# 저혈압 예측 알고리즘"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB-x1opNjaIa",
        "colab_type": "text"
      },
      "source": [
        "## 본 프로그램의 옵션들"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFKXGjvNjWuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MINUTES_AHEAD = 1  # 저혈압을 1분 전에 예측\n",
        "LSTM_NODES = 16\n",
        "BATCH_SIZE = 256\n",
        "MAX_CASES = 100  # 본 예제에서 사용할 최대 case 수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0mXIwV0jhvg",
        "colab_type": "text"
      },
      "source": [
        "## Case Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrGHCgBCjfIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab10b509-4654-4efb-f289-92a11d11dfc5"
      },
      "source": [
        "df_trks = pd.read_csv('https://api.vitaldb.net/v2/trks')  # 트랙 목록\n",
        "df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # 임상 정보\n",
        "\n",
        "caseids = list(\n",
        "    set(df_trks[df_trks['tname'] == 'Solar8000/ART_MBP']['caseid']) & \\\n",
        "    set(df_cases[df_cases['age'] > 18]['caseid']) & \\\n",
        "    set(df_cases[~df_cases['opname'].str.contains(\"transplant\")]['caseid'])\n",
        ")\n",
        "print('Total {} cases found'.format(len(caseids)))\n",
        "np.random.shuffle(caseids)  # caseid를 무작위로 섞음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 3452 cases found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwcgHzUfjpyE",
        "colab_type": "text"
      },
      "source": [
        "## 데이터셋 생성 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xVxKmNJjxQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97b7da8e-2b88-4f40-995b-890f73c414a1"
      },
      "source": [
        "def load_trk(tid, interval=1):\n",
        "    try:\n",
        "        url = 'https://api.vitaldb.net/' + tid\n",
        "        dtmbps = pd.read_csv(url).values\n",
        "    except:\n",
        "        return np.empty(0)\n",
        "    if len(dtmbps) == 0:\n",
        "        return np.empty(0)\n",
        "    dtmbps[:,0] /= interval  # convert time to row\n",
        "    trklen = int(np.nanmax(dtmbps[:,0])) + 1  # find maximum index (array length)\n",
        "    ret = np.full(trklen, np.nan)  # create a dense array\n",
        "    for idx, val in dtmbps:  # copy values\n",
        "        ret[int(idx)] = val\n",
        "    return ret\n",
        "\n",
        "# 최종 생성할 데이터셋\n",
        "x = []  # 각 레코드의 혈압 시계열 데이터\n",
        "y = []  # 각 레코드의 출력값 (3분 후 저혈압 발생 여부)\n",
        "valid_mask = []  # 각 샘플이 유효한지 여부 (유효하지 않은 샘플도 그림을 그리기 위해 추출함)\n",
        "y_caseid = []  # 각 레코드의 caseid\n",
        "\n",
        "# 최대로 로딩할 case 수\n",
        "ncase = min(MAX_CASES, len(caseids))\n",
        "icase = 0\n",
        "for caseid in caseids:\n",
        "    print('loading {} ({}/{})...'.format(caseid, icase + 1, ncase), flush=True, end='')\n",
        "\n",
        "    # 현 case의 ART_MBP 트랙을 로딩\n",
        "    tid = df_trks[(df_trks['caseid'] == caseid) & (df_trks['tname'] == 'Solar8000/ART_MBP')]['tid'].values[0]\n",
        "    mbps = load_trk(tid, 2)  # 2초 인터벌\n",
        "\n",
        "    # 2시간 이내의 case 들은 사용하지 않음\n",
        "    if len(mbps) < 360:\n",
        "        print('case len < 2h')\n",
        "        continue\n",
        "\n",
        "    # a-line 연결 전 샘플들을 제거\n",
        "    with np.errstate(invalid='ignore'):\n",
        "        mbps[mbps < 40] = np.nan\n",
        "\n",
        "    # 처음과 마지막의 결측값을 제거\n",
        "    case_valid_mask = ~np.isnan(mbps)\n",
        "    mbps = mbps[(np.cumsum(case_valid_mask) != 0) & (np.cumsum(case_valid_mask[::-1])[::-1] != 0)]\n",
        "\n",
        "    # 중간 결측값을 직전값으로 대체\n",
        "    mbps = pd.DataFrame(mbps).fillna(method='ffill').values.flatten()\n",
        "    \n",
        "    # event data 뽑음\n",
        "    case_sample = 0\n",
        "    case_event = 0\n",
        "    # 입력 혈압 (20초 = 10샘플)\n",
        "    # 중간 윈도우 (MINUTES_AHEAD * 30 샘플)\n",
        "    # 결과 혈압 (1분 = 30샘플)\n",
        "    for i in range(len(mbps) - (10 + MINUTES_AHEAD * 30 + 30)):\n",
        "        segx = mbps[i:i + 10]\n",
        "\n",
        "        # y는 mbp 기준\n",
        "        segy = mbps[i + 10 + MINUTES_AHEAD * 30:i + 10 + MINUTES_AHEAD * 30 + 30]\n",
        "\n",
        "        # 중간에 nan 있으면?\n",
        "        valid = True\n",
        "        if np.any(segx > 150):  # 어떤 샘플이든 150 이상이면?\n",
        "            valid = False\n",
        "        elif np.any(segy > 150):  # 어떤 샘플이든 150 이상이면?\n",
        "            valid = False\n",
        "        elif np.any(np.abs(np.diff(segx)) > 50):  # 2초만에 30 mmHg 이상 변하면\n",
        "            valid = False\n",
        "        elif np.any(np.abs(np.diff(segy)) > 50):  # 2초만에 30 mmHg 이상 변하면\n",
        "            valid = False\n",
        "        elif (segx < 40).all():  # 어떤 샘플이든 40 이하이면?\n",
        "            valid = False\n",
        "        elif (segy < 40).all():  # 어떤 샘플이든 40 이하이면?\n",
        "            valid = False\n",
        "\n",
        "        evt = np.nanmax(segy) < 65\n",
        "        x.append(segx)  # 20초 segment\n",
        "        y.append(evt)  # 최대 값이 65 미만이어야 함\n",
        "        valid_mask.append(valid)\n",
        "        y_caseid.append(caseid)\n",
        "        \n",
        "        if valid:\n",
        "            case_sample += 1\n",
        "            if evt:\n",
        "                case_event += 1\n",
        "\n",
        "    if case_sample > 0:\n",
        "        icase += 1\n",
        "        print(\"{} samples {} events ({:.1f}%)\".format(case_sample, case_event, 100*case_event/case_sample))\n",
        "    else:\n",
        "        print('all nan')\n",
        "\n",
        "    if icase >= ncase:\n",
        "        break\n",
        "\n",
        "# 최종적으로 로딩 된 caseid\n",
        "caseids = np.unique(y_caseid)\n",
        "\n",
        "# 입력 데이터셋을 python array 에서 numpy array로 변경\n",
        "x = np.array(x)[...,None]  # LSTM 에 입력으로 넣으려면 3차원으로 만들어야함\n",
        "y = np.array(y) \n",
        "valid_mask = np.array(valid_mask)\n",
        "y_caseid = np.array(y_caseid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading 2548 (1/100)...all nan\n",
            "loading 3107 (1/100)...6594 samples 187 events (2.8%)\n",
            "loading 5871 (2/100)...5163 samples 0 events (0.0%)\n",
            "loading 1687 (3/100)...4847 samples 1 events (0.0%)\n",
            "loading 5944 (4/100)...7641 samples 633 events (8.3%)\n",
            "loading 1673 (5/100)...3601 samples 779 events (21.6%)\n",
            "loading 2012 (6/100)...1174 samples 379 events (32.3%)\n",
            "loading 3125 (7/100)...7299 samples 0 events (0.0%)\n",
            "loading 774 (8/100)...9359 samples 987 events (10.5%)\n",
            "loading 6330 (9/100)...4201 samples 41 events (1.0%)\n",
            "loading 2462 (10/100)...7059 samples 35 events (0.5%)\n",
            "loading 2845 (11/100)...5136 samples 0 events (0.0%)\n",
            "loading 4137 (12/100)...7916 samples 6 events (0.1%)\n",
            "loading 2712 (13/100)...4406 samples 613 events (13.9%)\n",
            "loading 2680 (14/100)...6958 samples 759 events (10.9%)\n",
            "loading 5292 (15/100)...2449 samples 52 events (2.1%)\n",
            "loading 808 (16/100)...7049 samples 444 events (6.3%)\n",
            "loading 439 (17/100)...4177 samples 79 events (1.9%)\n",
            "loading 2595 (18/100)...6971 samples 0 events (0.0%)\n",
            "loading 1505 (19/100)...1766 samples 32 events (1.8%)\n",
            "loading 5490 (20/100)...6327 samples 259 events (4.1%)\n",
            "loading 658 (21/100)...all nan\n",
            "loading 4982 (21/100)...4056 samples 332 events (8.2%)\n",
            "loading 4457 (22/100)...6505 samples 219 events (3.4%)\n",
            "loading 3740 (23/100)...9569 samples 163 events (1.7%)\n",
            "loading 3255 (24/100)...10022 samples 45 events (0.4%)\n",
            "loading 4717 (25/100)...4441 samples 56 events (1.3%)\n",
            "loading 2201 (26/100)...6365 samples 1439 events (22.6%)\n",
            "loading 1039 (27/100)...5526 samples 960 events (17.4%)\n",
            "loading 5831 (28/100)...9001 samples 434 events (4.8%)\n",
            "loading 1194 (29/100)...9647 samples 394 events (4.1%)\n",
            "loading 20 (30/100)...12117 samples 1255 events (10.4%)\n",
            "loading 1642 (31/100)...4456 samples 116 events (2.6%)\n",
            "loading 868 (32/100)...2523 samples 523 events (20.7%)\n",
            "loading 5747 (33/100)...case len < 2h\n",
            "loading 684 (33/100)...3127 samples 0 events (0.0%)\n",
            "loading 2569 (34/100)...1704 samples 0 events (0.0%)\n",
            "loading 3336 (35/100)...4739 samples 410 events (8.7%)\n",
            "loading 5131 (36/100)...6320 samples 88 events (1.4%)\n",
            "loading 2778 (37/100)...11789 samples 5 events (0.0%)\n",
            "loading 2295 (38/100)...2801 samples 355 events (12.7%)\n",
            "loading 3832 (39/100)...10271 samples 17 events (0.2%)\n",
            "loading 3691 (40/100)...4381 samples 113 events (2.6%)\n",
            "loading 3287 (41/100)...13023 samples 8 events (0.1%)\n",
            "loading 1250 (42/100)...all nan\n",
            "loading 382 (42/100)...8354 samples 299 events (3.6%)\n",
            "loading 347 (43/100)...1174 samples 0 events (0.0%)\n",
            "loading 6104 (44/100)...5334 samples 72 events (1.3%)\n",
            "loading 5765 (45/100)...2842 samples 118 events (4.2%)\n",
            "loading 1884 (46/100)...8896 samples 454 events (5.1%)\n",
            "loading 6192 (47/100)...1030 samples 1 events (0.1%)\n",
            "loading 427 (48/100)...4488 samples 0 events (0.0%)\n",
            "loading 4265 (49/100)...6810 samples 509 events (7.5%)\n",
            "loading 1040 (50/100)...4393 samples 31 events (0.7%)\n",
            "loading 4620 (51/100)...2791 samples 69 events (2.5%)\n",
            "loading 1392 (52/100)...6027 samples 9 events (0.1%)\n",
            "loading 1873 (53/100)...7098 samples 254 events (3.6%)\n",
            "loading 5830 (54/100)...all nan\n",
            "loading 2601 (54/100)...7271 samples 3 events (0.0%)\n",
            "loading 5610 (55/100)...1768 samples 168 events (9.5%)\n",
            "loading 74 (56/100)...8096 samples 7 events (0.1%)\n",
            "loading 781 (57/100)...2957 samples 601 events (20.3%)\n",
            "loading 2126 (58/100)...all nan\n",
            "loading 5572 (58/100)...5090 samples 209 events (4.1%)\n",
            "loading 1303 (59/100)...4585 samples 28 events (0.6%)\n",
            "loading 2471 (60/100)...3034 samples 130 events (4.3%)\n",
            "loading 6259 (61/100)...4974 samples 128 events (2.6%)\n",
            "loading 5254 (62/100)...5307 samples 688 events (13.0%)\n",
            "loading 2828 (63/100)...6678 samples 139 events (2.1%)\n",
            "loading 2284 (64/100)...3059 samples 0 events (0.0%)\n",
            "loading 4201 (65/100)...5178 samples 0 events (0.0%)\n",
            "loading 2299 (66/100)...2360 samples 0 events (0.0%)\n",
            "loading 1620 (67/100)...6337 samples 25 events (0.4%)\n",
            "loading 2847 (68/100)...9886 samples 247 events (2.5%)\n",
            "loading 4953 (69/100)...10529 samples 191 events (1.8%)\n",
            "loading 1331 (70/100)...7475 samples 1 events (0.0%)\n",
            "loading 5697 (71/100)...all nan\n",
            "loading 3045 (71/100)...2686 samples 0 events (0.0%)\n",
            "loading 4718 (72/100)...4097 samples 461 events (11.3%)\n",
            "loading 6153 (73/100)...5458 samples 175 events (3.2%)\n",
            "loading 1568 (74/100)...3959 samples 199 events (5.0%)\n",
            "loading 286 (75/100)...5486 samples 42 events (0.8%)\n",
            "loading 4960 (76/100)...6908 samples 148 events (2.1%)\n",
            "loading 1745 (77/100)...8485 samples 485 events (5.7%)\n",
            "loading 5678 (78/100)...23460 samples 329 events (1.4%)\n",
            "loading 6206 (79/100)...1882 samples 82 events (4.4%)\n",
            "loading 5284 (80/100)...8967 samples 1636 events (18.2%)\n",
            "loading 5568 (81/100)...5502 samples 234 events (4.3%)\n",
            "loading 1219 (82/100)...7065 samples 2 events (0.0%)\n",
            "loading 234 (83/100)...7115 samples 114 events (1.6%)\n",
            "loading 680 (84/100)...2392 samples 286 events (12.0%)\n",
            "loading 4116 (85/100)...4440 samples 39 events (0.9%)\n",
            "loading 5108 (86/100)...8572 samples 418 events (4.9%)\n",
            "loading 5140 (87/100)...7797 samples 3 events (0.0%)\n",
            "loading 629 (88/100)...13271 samples 2313 events (17.4%)\n",
            "loading 1614 (89/100)...4070 samples 0 events (0.0%)\n",
            "loading 4443 (90/100)...6135 samples 11 events (0.2%)\n",
            "loading 4111 (91/100)...4238 samples 0 events (0.0%)\n",
            "loading 1160 (92/100)...5954 samples 625 events (10.5%)\n",
            "loading 1488 (93/100)...4447 samples 0 events (0.0%)\n",
            "loading 217 (94/100)...7369 samples 216 events (2.9%)\n",
            "loading 4149 (95/100)...5990 samples 338 events (5.6%)\n",
            "loading 5462 (96/100)...4000 samples 0 events (0.0%)\n",
            "loading 2549 (97/100)...2415 samples 0 events (0.0%)\n",
            "loading 6385 (98/100)...9593 samples 777 events (8.1%)\n",
            "loading 2500 (99/100)...1928 samples 2 events (0.1%)\n",
            "loading 5753 (100/100)...5501 samples 657 events (11.9%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2yXKrxSkFV_",
        "colab_type": "text"
      },
      "source": [
        "## Training / Testing set 으로 나눔"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhQRw4QMkJTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee7a1cfb-1b76-4694-ab86-7df4b4bbfdc0"
      },
      "source": [
        "# train, test set 을 case 단위로 나눔\n",
        "ntest = int(ncase * 0.2)\n",
        "ntrain = ncase - ntest\n",
        "caseids_train = caseids[:ntrain]\n",
        "caseids_test = caseids[ncase - ntest:ncase]\n",
        "\n",
        "# train set과 test set 으로 나눔\n",
        "train_mask = np.array([caseid in caseids_train for caseid in y_caseid])\n",
        "test_mask = np.array([caseid in caseids_test for caseid in y_caseid])\n",
        "\n",
        "# test set은 그림을 그려야 하므로 invalid 값까지 전체 데이터도 필요\n",
        "test_x = x[test_mask]\n",
        "test_y = y[test_mask]\n",
        "test_y_caseid = y_caseid[test_mask]\n",
        "\n",
        "# valid 한 값만 포함하는 배열 (학습 및 성능 평가시 사용)\n",
        "train_x_valid = x[train_mask & valid_mask]\n",
        "train_y_valid = y[train_mask & valid_mask]\n",
        "test_x_valid = x[test_mask & valid_mask]\n",
        "test_y_valid = y[test_mask & valid_mask]\n",
        "\n",
        "testname = '{}cases {}ahead batchsize={} total {}, train {} ({} events {:.1f}%), test {} ({} events {:.1f}%)'.format(MAX_CASES, MINUTES_AHEAD, BATCH_SIZE, len(y), len(train_y_valid), sum(train_y_valid), 100*np.mean(train_y_valid), len(test_y_valid), sum(test_y_valid), 100*np.mean(test_y_valid))\n",
        "testname"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'100cases 1ahead batchsize=256 total 630146, train 475296 (20186 events 4.2%), test 120183 (6005 events 5.0%)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW8w8ZuDkQ6e",
        "colab_type": "text"
      },
      "source": [
        "## 모델 생성 및 학습 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpxNAdARkTEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "531d467d-2202-448f-dea8-b17ac779c749"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, LSTM, Input, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "# 임시 폴더를 생성\n",
        "tempdir = 'output'\n",
        "if not os.path.exists(tempdir):\n",
        "    os.mkdir(tempdir)\n",
        "weight_path = tempdir + \"/weights.hdf5\"\n",
        "\n",
        "# build a model\n",
        "model = Sequential()\n",
        "model.add(LSTM(LSTM_NODES, input_shape=x.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "hist = model.fit(train_x_valid, train_y_valid, validation_split=0.1, epochs=100, batch_size=BATCH_SIZE, class_weight={0:1, 1:5},\n",
        "                 callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weight_path, verbose=1, save_best_only=True),\n",
        "                            EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')])\n",
        "\n",
        "# 최적의 모델을 저장\n",
        "model.load_weights(weight_path)\n",
        "open(tempdir + \"/model.json\", \"wt\").write(model.to_json())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1669/1671 [============================>.] - ETA: 0s - loss: 0.2659 - accuracy: 0.9415 - auc: 0.9469\n",
            "Epoch 00001: val_loss improved from inf to 0.15444, saving model to output/weights.hdf5\n",
            "1671/1671 [==============================] - 10s 6ms/step - loss: 0.2658 - accuracy: 0.9415 - auc: 0.9469 - val_loss: 0.1544 - val_accuracy: 0.9429 - val_auc: 0.9700\n",
            "Epoch 2/100\n",
            "1668/1671 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9512 - auc: 0.9582\n",
            "Epoch 00002: val_loss improved from 0.15444 to 0.10921, saving model to output/weights.hdf5\n",
            "1671/1671 [==============================] - 10s 6ms/step - loss: 0.2206 - accuracy: 0.9512 - auc: 0.9582 - val_loss: 0.1092 - val_accuracy: 0.9545 - val_auc: 0.9704\n",
            "Epoch 3/100\n",
            "1663/1671 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9496 - auc: 0.9582\n",
            "Epoch 00003: val_loss did not improve from 0.10921\n",
            "1671/1671 [==============================] - 10s 6ms/step - loss: 0.2183 - accuracy: 0.9496 - auc: 0.9581 - val_loss: 0.1679 - val_accuracy: 0.9315 - val_auc: 0.9702\n",
            "Epoch 4/100\n",
            "1662/1671 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9489 - auc: 0.9583\n",
            "Epoch 00004: val_loss did not improve from 0.10921\n",
            "1671/1671 [==============================] - 10s 6ms/step - loss: 0.2164 - accuracy: 0.9489 - auc: 0.9582 - val_loss: 0.1564 - val_accuracy: 0.9360 - val_auc: 0.9703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxyxDHv3kcrx",
        "colab_type": "text"
      },
      "source": [
        "## 모델 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djtCfcu1kfLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78d817e7-9cac-4681-b7ef-f8d1fa6823a4"
      },
      "source": [
        "from sklearn.metrics import auc, classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, f1_score, precision_recall_curve\n",
        "\n",
        "# test을 한번에 예측\n",
        "test_y_pred = model.predict(test_x_valid).flatten()\n",
        "\n",
        "precision, recall, thmbps = precision_recall_curve(test_y_valid, test_y_pred)\n",
        "auprc = auc(recall, precision)\n",
        "\n",
        "fpr, tpr, thmbps = roc_curve(test_y_valid, test_y_pred)\n",
        "auroc = auc(fpr, tpr)\n",
        "\n",
        "thval = 0.5\n",
        "f1 = f1_score(test_y_valid, test_y_pred > thval)\n",
        "acc = accuracy_score(test_y_valid, test_y_pred > thval)\n",
        "tn, fp, fn, tp = confusion_matrix(test_y_valid, test_y_pred > thval).ravel()\n",
        "\n",
        "testres = 'auroc={:.3f}, auprc={:.3f} acc={:.3f}, F1={:.3f}, PPV={:.1f}, NPV={:.1f}, TN={}, fp={}, fn={}, TP={}'.format(auroc, auprc, acc, f1, tp/(tp+fp)*100, tn/(tn+fn)*100, tn, fp, fn, tp)\n",
        "print(testres)\n",
        "\n",
        "# 최종 폴더명을 변경\n",
        "odir = testname + ' ' + testres\n",
        "os.rename(tempdir, odir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auroc=0.954, auprc=0.488 acc=0.953, F1=0.441, PPV=55.0, NPV=96.7, TN=112363, fp=1815, fn=3790, TP=2215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRE-MRKMkjTm",
        "colab_type": "text"
      },
      "source": [
        "## 그래프 그림"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TREy3Tuhklqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "cbd82f78-9070-4948-ad36-bbbbd165a8da"
      },
      "source": [
        "# auroc curve\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.savefig('{}/auroc.png'.format(odir))\n",
        "plt.close()\n",
        "\n",
        "# auprc curve\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.savefig('{}/auprc.png'.format(odir))\n",
        "plt.close()\n",
        "\n",
        "# 각 case 그림\n",
        "for caseid in caseids_test:\n",
        "    case_mask = (y_caseid == caseid)\n",
        "    case_len = np.sum(case_mask)\n",
        "    if case_len == 0:\n",
        "        continue\n",
        "\n",
        "    # case 내의 x, y, valid_mask 를 만든다\n",
        "    case_x = x[case_mask]\n",
        "    case_y = y[case_mask]\n",
        "    case_valid_mask = valid_mask[case_mask]\n",
        "    \n",
        "    # case 에러를 구하고 출력\n",
        "    case_predy = model.predict(case_x).flatten()\n",
        "    case_rmse = np.nanmean((case_y - case_predy) ** 2) ** 0.5\n",
        "    print('{}\\t{}\\t'.format(caseid, case_rmse))\n",
        "\n",
        "    # 그림 생성\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    plt.xlim([0, case_len + MINUTES_AHEAD * 30])\n",
        "    t = np.arange(0, case_len)\n",
        "\n",
        "    # 저혈압 상태일 때를 붉은 반투명 배경으로\n",
        "    ax1 = plt.gca()\n",
        "    for i in range(len(case_y)):\n",
        "        if case_y[i]:\n",
        "            ax1.axvspan(i + MINUTES_AHEAD * 30, i + MINUTES_AHEAD * 30 + 1, color='r', alpha=0.1, lw=0)\n",
        "\n",
        "    # 65 mmHg 가로선\n",
        "    ax1.axhline(y=65, color='r', alpha=0.5)\n",
        "    ax1.plot(t + 10, case_x[:,-1], color='r')\n",
        "    ax1.set_ylim([0, 150])\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    \n",
        "    # valid 한 샘플만 그린다\n",
        "    case_predy[~case_valid_mask] = np.nan\n",
        "    ax2.plot(t, case_predy)\n",
        "    ax2.set_ylim([0, 1])\n",
        "    \n",
        "    # 그림 저장\n",
        "    plt.savefig('{}/{:.3f}_{}.png'.format(odir, case_rmse, caseid))\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5284\t0.2533635869412729\t\n",
            "5292\t0.13899401065775044\t\n",
            "5462\t0.004232602589811871\t\n",
            "5490\t0.1951201349900689\t\n",
            "5568\t0.2012672753649524\t\n",
            "5572\t0.16351170839994836\t\n",
            "5610\t0.2840959091180007\t\n",
            "5678\t0.09533921457560449\t\n",
            "5753\t0.284343685270462\t\n",
            "5765\t0.17167864767720956\t\n",
            "5831\t0.21194318052726469\t\n",
            "5871\t0.0007153860609217485\t\n",
            "5944\t0.18633765310241648\t\n",
            "6104\t0.10840770320984967\t\n",
            "6153\t0.17462491535950658\t\n",
            "6192\t0.07012890648734289\t\n",
            "6206\t0.2434751443440634\t\n",
            "6259\t0.13802457225581619\t\n",
            "6330\t0.13473761308873922\t\n",
            "6385\t0.24839586952778922\t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}